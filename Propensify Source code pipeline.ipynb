{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c721de0",
   "metadata": {},
   "source": [
    "## Source Code pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5094e8e2",
   "metadata": {},
   "source": [
    "#Importing necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e8fb060",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c5a54eed",
   "metadata": {},
   "source": [
    "Defining a function to treat missing values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f46fd8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def treat_missing_values(data):\n",
    "    columns_to_keep = ['custAge', 'profession', 'marital', 'schooling', 'default', 'housing',\n",
    "                       'loan', 'contact', 'month', 'day_of_week', 'campaign', 'pdays', 'previous',\n",
    "                       'poutcome', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx',\n",
    "                       'euribor3m', 'nr.employed', 'pmonths', 'pastEmail', 'responded']\n",
    "\n",
    "    data = data[columns_to_keep]\n",
    "\n",
    "    # Calculate the mean for each category in the 'profession' column\n",
    "    mean_by_profession = train_data.groupby('profession')['custAge'].mean().round()\n",
    "\n",
    "    # Impute mean values for null categories in the 'profession' column using lambda function\n",
    "    data.loc[data['custAge'].isnull(), 'custAge'] = data.apply(lambda row: mean_by_profession.get(row['profession'], row['custAge']) if pd.isna(row['custAge']) else row['custAge'], axis=1)\n",
    "\n",
    "    # Imputation of missing values in education based on profession\n",
    "    mapping = {\n",
    "    'blue-collar' : 'basic.4y',\n",
    "    'blue-collar' : 'basic.6y',\n",
    "    'blue-collar' : 'basic.9y',\n",
    "    'self-employed': 'illiterate',\n",
    "    'technician'   : 'professional.course',\n",
    "    'admin.'        : 'university.degree',\n",
    "    'services'      : 'high.school',\n",
    "    'management'    : 'university.degree',\n",
    "    'retired'       : 'unknown',\n",
    "    'entrepreneur'  : 'university.degree'\n",
    "             }\n",
    "\n",
    "     # Using fillna method to fill nulll values by mapping to above dictionary \n",
    "\n",
    "    train_data['schooling'].fillna(train_data['profession'].map(mapping), inplace=True)\n",
    "    \n",
    "    train_data['schooling'].fillna('unknown', inplace=True)\n",
    "    \n",
    "    import numpy as np\n",
    "\n",
    "    # Define the list of days\n",
    "    days_list = ['mon', 'tue', 'wed', 'thu', 'fri']\n",
    "\n",
    "    # Replace null values in 'day_of_week' column with random choices\n",
    "    train_data['day_of_week'] = train_data['day_of_week'].fillna(np.random.choice(days_list))\n",
    "\n",
    "    \n",
    "    \n",
    "    # Combining 'unknown' category with 'single' category\n",
    "    train_data['marital'] = train_data['marital'].replace('unknown', 'single')\n",
    "    \n",
    "    \n",
    "    \n",
    "     # Drop remaining missing values\n",
    "    data = data.dropna()\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1aaeec95",
   "metadata": {},
   "source": [
    "Defining a function to label encode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d304e311",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoding(data):\n",
    "    # pdays\n",
    "    conditions = [\n",
    "        (data['pdays'] == 999),\n",
    "        (data['pdays'] < 10),\n",
    "        (data['pdays'] >= 10)\n",
    "    ]\n",
    "\n",
    "    choices = ['first visit', 'less than 10 days', 'greater than 10 days']\n",
    "\n",
    "    # Create the 'pduration' column based on conditions\n",
    "    data['pduration'] = np.select(conditions, choices, default='unknown')\n",
    "\n",
    "    # pmonths\n",
    "    conditions = [\n",
    "        (data['pmonths'] == 999),\n",
    "        (data['pmonths'] <= 0.3),\n",
    "        (data['pmonths'] > 0.3)\n",
    "    ]\n",
    "\n",
    "    choices = ['first visit', 'less than 2 months', 'greater than 2 months']\n",
    "\n",
    "    # Create the 'pduration_m' column based on conditions\n",
    "    data['pduration_m'] = np.select(conditions, choices, default='unknown')\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ee6928d4",
   "metadata": {},
   "source": [
    "Defining a function for feature transformation,\n",
    "using one hot encoding for categorical and standarscaler for continuous variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50eb2374",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "def feature_transformation(data):\n",
    "    # Dropping target and unnecessary columns\n",
    "    X = data.drop(['responded', 'pdays', 'pmonths'], axis=1)\n",
    "    y = data['responded']\n",
    "\n",
    "    # One-hot encode categorical columns\n",
    "    X_encoded = pd.get_dummies(X, columns=['loan', 'marital', 'schooling', 'default', 'housing', 'day_of_week',\n",
    "                                           'poutcome', 'pduration', 'pduration_m', 'profession', 'month', 'contact'],\n",
    "                               drop_first=True)\n",
    "\n",
    "    # Continuous columns for normalization\n",
    "    continuous_columns = ['custAge', 'campaign', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx',\n",
    "                          'euribor3m', 'nr.employed', 'pastEmail']\n",
    "\n",
    "    # Extracting the continuous columns from X_encoded\n",
    "    X_continuous = X_encoded[continuous_columns]\n",
    "\n",
    "    # StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Fit and transform\n",
    "    X_continuous_normalized = scaler.fit_transform(X_continuous)\n",
    "\n",
    "    # Replacing the original continuous columns in X_encoded with the normalized ones\n",
    "    X_encoded[continuous_columns] = X_continuous_normalized\n",
    "\n",
    "    return X_encoded, y\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b293cb62",
   "metadata": {},
   "source": [
    "Importing libraries\n",
    "Defining a function to train the model.\n",
    "Using Random forest classifier and Support vector machine classifier for the classification task on the targetted column.\n",
    "Then using Voting classifer to ensemble performing Hard voting.\n",
    "Using Smoteenn to handle imablaced dataset.\n",
    "Scoring For Accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a717066",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.combine import SMOTEENN\n",
    "import numpy as np\n",
    "\n",
    "def train_propensify_model(X_encoded, y):\n",
    "    # Set a random seed for reproducibility\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create a Random Forest classifier\n",
    "    rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "    # Create a Support Vector Machine (SVM) classifier with RBF kernel\n",
    "    svm_classifier = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "\n",
    "    # Ensemble the classifiers using a VotingClassifier\n",
    "    ensemble_classifier = VotingClassifier(estimators=[\n",
    "        ('rf', rf_classifier),\n",
    "        ('svm', svm_classifier)\n",
    "    ], voting='hard')  # 'hard' for probability voting\n",
    "\n",
    "    # Define the preprocessing steps and classifiers for the pipeline\n",
    "    preprocessing_steps = [('smoteenn', SMOTEENN(random_state=42, sampling_strategy=0.5)),\n",
    "                           ('ensemble_classifier', ensemble_classifier)]\n",
    "    pipeline = ImbPipeline(preprocessing_steps)\n",
    "\n",
    "    # Define the parameter grid for GridSearchCV\n",
    "    param_grid = {\n",
    "        'smoteenn__sampling_strategy': [0.5],\n",
    "        'ensemble_classifier__voting': ['hard'],\n",
    "        'ensemble_classifier__rf__n_estimators': [50],\n",
    "        'ensemble_classifier__rf__max_depth': [None, 2],\n",
    "        'ensemble_classifier__rf__min_samples_split': [2, 3],\n",
    "    }\n",
    "\n",
    "    # Create GridSearchCV object\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "    # Fit GridSearchCV on the training data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    return grid_search\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b1450145",
   "metadata": {},
   "source": [
    "Fetching the train and test data that was provided.\n",
    "Also adding a column named responded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75272b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load training and testing datasets\n",
    "train_data = pd.read_excel(r\"C:\\\\Users\\\\veenu\\\\Downloads\\\\Propensify\\\\train.xlsx\")\n",
    "test_data = pd.read_excel(r\"C:\\\\Users\\\\veenu\\\\Downloads\\\\Propensify\\\\test.xlsx\")\n",
    "\n",
    "# New column 'responded' to the test data and assigning a value ('yes' or 'no')\n",
    "test_data['responded'] = 'yes'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cc06d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['propensify_model.joblib']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from joblib import dump\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# preprocessing pipeline\n",
    "preprocessing_pipeline = Pipeline([\n",
    "    ('missing_values', FunctionTransformer(func=treat_missing_values)),\n",
    "    ('label_encoding', FunctionTransformer(func=label_encoding)),\n",
    "    ('feature_transformation', FunctionTransformer(func=feature_transformation)),\n",
    "])\n",
    "\n",
    "# Fitting the pipeline on the training data\n",
    "X_train_transformed, y_train = preprocessing_pipeline.fit_transform(train_data)\n",
    "\n",
    "# Training the model \n",
    "trained_model = train_propensify_model(X_train_transformed, y_train)\n",
    "\n",
    "# Saving pipeline\n",
    "joblib.dump(preprocessing_pipeline, 'preprocessing_pipeline.joblib')\n",
    "\n",
    "# Saving the trained model\n",
    "joblib.dump(trained_model, 'propensify_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9712ef37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loaded_model = joblib.load('propensify_model.joblib')\n",
    "\n",
    "preprocessing_pipeline = joblib.load('preprocessing_pipeline.joblib')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "03685f0e",
   "metadata": {},
   "source": [
    "Pipeline tramsformations test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4c1423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transformed, _ = preprocessing_pipeline.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7abdff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = loaded_model.predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f1782eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custAge</th>\n",
       "      <th>campaign</th>\n",
       "      <th>previous</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>pastEmail</th>\n",
       "      <th>loan_unknown</th>\n",
       "      <th>...</th>\n",
       "      <th>month_dec</th>\n",
       "      <th>month_jul</th>\n",
       "      <th>month_jun</th>\n",
       "      <th>month_mar</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>contact_telephone</th>\n",
       "      <th>Predicted_Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.525480</td>\n",
       "      <td>-0.202662</td>\n",
       "      <td>1.665493</td>\n",
       "      <td>-2.211954</td>\n",
       "      <td>-2.066289</td>\n",
       "      <td>2.296557</td>\n",
       "      <td>-1.633517</td>\n",
       "      <td>-2.064448</td>\n",
       "      <td>1.312616</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.051504</td>\n",
       "      <td>-0.559551</td>\n",
       "      <td>1.665493</td>\n",
       "      <td>-1.195537</td>\n",
       "      <td>-1.179859</td>\n",
       "      <td>-1.240710</td>\n",
       "      <td>-1.322916</td>\n",
       "      <td>-0.936747</td>\n",
       "      <td>1.312616</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.051141</td>\n",
       "      <td>-0.559551</td>\n",
       "      <td>-0.350019</td>\n",
       "      <td>0.837298</td>\n",
       "      <td>-0.229619</td>\n",
       "      <td>0.937729</td>\n",
       "      <td>0.772915</td>\n",
       "      <td>0.846016</td>\n",
       "      <td>-0.277382</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.104951</td>\n",
       "      <td>-0.559551</td>\n",
       "      <td>-0.350019</td>\n",
       "      <td>-0.115593</td>\n",
       "      <td>-0.650415</td>\n",
       "      <td>-0.334824</td>\n",
       "      <td>0.305574</td>\n",
       "      <td>0.399634</td>\n",
       "      <td>-0.277382</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.051141</td>\n",
       "      <td>-0.559551</td>\n",
       "      <td>-0.350019</td>\n",
       "      <td>0.837298</td>\n",
       "      <td>0.587829</td>\n",
       "      <td>-0.485805</td>\n",
       "      <td>0.772339</td>\n",
       "      <td>0.846016</td>\n",
       "      <td>-0.277382</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32943</th>\n",
       "      <td>-0.420348</td>\n",
       "      <td>-0.202662</td>\n",
       "      <td>-0.350019</td>\n",
       "      <td>-1.195537</td>\n",
       "      <td>-0.865986</td>\n",
       "      <td>-1.434828</td>\n",
       "      <td>-1.250309</td>\n",
       "      <td>-0.936747</td>\n",
       "      <td>-0.277382</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32944</th>\n",
       "      <td>-0.840877</td>\n",
       "      <td>-0.202662</td>\n",
       "      <td>-0.350019</td>\n",
       "      <td>0.837298</td>\n",
       "      <td>-0.229619</td>\n",
       "      <td>0.937729</td>\n",
       "      <td>0.774068</td>\n",
       "      <td>0.846016</td>\n",
       "      <td>-0.277382</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32947</th>\n",
       "      <td>-0.840877</td>\n",
       "      <td>-0.202662</td>\n",
       "      <td>-0.350019</td>\n",
       "      <td>-1.195537</td>\n",
       "      <td>-1.179859</td>\n",
       "      <td>-1.240710</td>\n",
       "      <td>-1.339051</td>\n",
       "      <td>-0.936747</td>\n",
       "      <td>-0.277382</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32948</th>\n",
       "      <td>-0.840877</td>\n",
       "      <td>-0.559551</td>\n",
       "      <td>-0.350019</td>\n",
       "      <td>0.837298</td>\n",
       "      <td>1.531170</td>\n",
       "      <td>-0.291687</td>\n",
       "      <td>0.770034</td>\n",
       "      <td>0.846016</td>\n",
       "      <td>-0.277382</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32949</th>\n",
       "      <td>-1.576803</td>\n",
       "      <td>-0.202662</td>\n",
       "      <td>-0.350019</td>\n",
       "      <td>-1.894323</td>\n",
       "      <td>-1.059139</td>\n",
       "      <td>-0.076000</td>\n",
       "      <td>-1.361525</td>\n",
       "      <td>-1.253222</td>\n",
       "      <td>-0.277382</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20845 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        custAge  campaign  previous  emp.var.rate  cons.price.idx  \\\n",
       "1     -0.525480 -0.202662  1.665493     -2.211954       -2.066289   \n",
       "2      1.051504 -0.559551  1.665493     -1.195537       -1.179859   \n",
       "3     -1.051141 -0.559551 -0.350019      0.837298       -0.229619   \n",
       "4     -0.104951 -0.559551 -0.350019     -0.115593       -0.650415   \n",
       "7     -1.051141 -0.559551 -0.350019      0.837298        0.587829   \n",
       "...         ...       ...       ...           ...             ...   \n",
       "32943 -0.420348 -0.202662 -0.350019     -1.195537       -0.865986   \n",
       "32944 -0.840877 -0.202662 -0.350019      0.837298       -0.229619   \n",
       "32947 -0.840877 -0.202662 -0.350019     -1.195537       -1.179859   \n",
       "32948 -0.840877 -0.559551 -0.350019      0.837298        1.531170   \n",
       "32949 -1.576803 -0.202662 -0.350019     -1.894323       -1.059139   \n",
       "\n",
       "       cons.conf.idx  euribor3m  nr.employed  pastEmail  loan_unknown  ...  \\\n",
       "1           2.296557  -1.633517    -2.064448   1.312616         False  ...   \n",
       "2          -1.240710  -1.322916    -0.936747   1.312616         False  ...   \n",
       "3           0.937729   0.772915     0.846016  -0.277382         False  ...   \n",
       "4          -0.334824   0.305574     0.399634  -0.277382         False  ...   \n",
       "7          -0.485805   0.772339     0.846016  -0.277382         False  ...   \n",
       "...              ...        ...          ...        ...           ...  ...   \n",
       "32943      -1.434828  -1.250309    -0.936747  -0.277382         False  ...   \n",
       "32944       0.937729   0.774068     0.846016  -0.277382         False  ...   \n",
       "32947      -1.240710  -1.339051    -0.936747  -0.277382         False  ...   \n",
       "32948      -0.291687   0.770034     0.846016  -0.277382         False  ...   \n",
       "32949      -0.076000  -1.361525    -1.253222  -0.277382         False  ...   \n",
       "\n",
       "       month_dec  month_jul  month_jun  month_mar  month_may  month_nov  \\\n",
       "1          False      False      False      False      False      False   \n",
       "2          False      False      False      False       True      False   \n",
       "3          False      False      False      False      False      False   \n",
       "4          False      False      False      False      False       True   \n",
       "7          False       True      False      False      False      False   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "32943      False      False      False      False      False      False   \n",
       "32944      False      False      False      False      False      False   \n",
       "32947      False      False      False      False       True      False   \n",
       "32948      False      False       True      False      False      False   \n",
       "32949      False      False       True      False      False      False   \n",
       "\n",
       "       month_oct  month_sep  contact_telephone  Predicted_Response  \n",
       "1          False       True              False                 yes  \n",
       "2          False      False              False                  no  \n",
       "3          False      False              False                  no  \n",
       "4          False      False              False                  no  \n",
       "7          False      False               True                  no  \n",
       "...          ...        ...                ...                 ...  \n",
       "32943      False      False              False                 yes  \n",
       "32944      False      False              False                  no  \n",
       "32947      False      False              False                  no  \n",
       "32948      False      False               True                  no  \n",
       "32949      False      False               True                 yes  \n",
       "\n",
       "[20845 rows x 57 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#column 'Predictions' to the preprocessed test data\n",
    "X_test_transformed['Predicted_Response'] = predictions\n",
    "\n",
    "#DataFrame with predictions\n",
    "X_test_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73c7b1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Predicted_Response\n",
       "no     17422\n",
       "yes     3423\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_transformed['Predicted_Response'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7d775f74",
   "metadata": {},
   "source": [
    "Saving as csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82d5881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'test_with.predictions.csv'\n",
    "X_test_transformed.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b7b98fd9",
   "metadata": {},
   "source": [
    "Saving as excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65110a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file_path = 'test_with.predictions.xlsx'\n",
    "X_test_transformed.to_excel(excel_file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
